{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('assets/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train[\"Date\"] = pd.to_datetime(train[\"Date\"], infer_datetime_format=True)\n",
    "train['Address'] = train['Address'].astype('category')\n",
    "train['Species'] = train['Species'].astype('category')\n",
    "train['Street'] = train['Street'].astype('category')\n",
    "train['Trap'] = train['Trap'].astype('category')\n",
    "train['AddressNumberAndStreet'] = train['AddressNumberAndStreet'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather = pd.read_csv('weather-nmo.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We need to create one line per date:\n",
    "station1 = weather[weather['Station']==1]\n",
    "station2 = weather[weather['Station']==2]\n",
    "station1 = station1.drop('Station', axis=1)\n",
    "station2 = station2.drop('Station', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "station1.columns = ['Date', 'st1_Tmax', 'st1_Tmin', 'st1_Tavg', 'st1_DewPoint', 'st1_WetBulb', 'st1_CodeSum',\n",
    "       'st1_SnowFall', 'st1_PrecipTotal', 'st1_StnPressure', 'st1_SeaLevel', 'st1_ResultSpeed',\n",
    "       'st1_ResultDir', 'st1_AvgSpeed', 'st1_Lat', 'st1_Long']\n",
    "station2.columns = ['Date', 'st2_Tmax', 'st2_Tmin', 'st2_Tavg', 'st2_DewPoint', 'st2_WetBulb', 'st2_CodeSum',\n",
    "       'st2_SnowFall', 'st2_PrecipTotal', 'st2_StnPressure', 'st2_SeaLevel', 'st2_ResultSpeed',\n",
    "       'st2_ResultDir', 'st2_AvgSpeed', 'st2_Lat', 'st2_Long']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather = pd.merge(station1, station2, on='Date')\n",
    "weather[\"Date\"] = pd.to_datetime(weather[\"Date\"], infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature engineer us some over time weather data\n",
    "weather = weather.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather['precip_avg'] = (weather['st1_PrecipTotal'] + weather['st2_PrecipTotal'])/2\n",
    "weather['2wk_precip'] = weather['precip_avg'].rolling(14, min_periods=1).sum()\n",
    "weather['4wk_precip'] = weather['precip_avg'].rolling(28, min_periods=1).sum()\n",
    "weather['90day_precip'] = weather['precip_avg'].rolling(90, min_periods=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather['temp_avg'] = (weather['st1_Tavg'] + weather['st2_Tavg'])/2\n",
    "weather['2wk_tavg'] = weather['temp_avg'].rolling(14, min_periods=1).mean()\n",
    "weather['4wk_tavg'] = weather['temp_avg'].rolling(28, min_periods=1).mean()\n",
    "weather['90day_tavg'] = weather['temp_avg'].rolling(90, min_periods=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather['tempmin_avg'] = (weather['st1_Tmin'] + weather['st2_Tmin'])/2\n",
    "weather['2wk_mintemp'] = weather['tempmin_avg'].rolling(14, min_periods=1).min()\n",
    "weather['4wk_mintemp'] = weather['tempmin_avg'].rolling(28, min_periods=1).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather['dew_avg'] = (weather['st1_DewPoint'] + weather['st2_DewPoint'])/2\n",
    "weather['2wk_dew'] = weather['dew_avg'].rolling(14, min_periods=1).mean()\n",
    "weather['4wk_dew'] = weather['dew_avg'].rolling(28, min_periods=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather = weather.reset_index()\n",
    "train = pd.merge(train, weather, how='left', on='Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_df = pd.get_dummies(train, columns=['Species'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_df['Month'] = final_df['Date'].dt.month\n",
    "final_df[\"Day\"] = final_df['Date'].dt.dayofyear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Location Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#our two origins (the locations with the most WNV activity) are Chicago O'Hare and Doty Ave.\n",
    "#the following values are their latitudes and longitudes\n",
    "ohare_lon = -87.890615\n",
    "ohare_lat = 41.974689\n",
    "doty_lon =-87.599862\n",
    "doty_lat=41.673408"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lat = train.Latitude\n",
    "lon = train.Longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#haversine takes two lat and longs and creates a distance, from the mean, in miles\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points \n",
    "    on the earth (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    # convert decimal degrees to radians \n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "    # haversine formula \n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a)) \n",
    "    mi = 3956   * c #Radius of earth in miles. Use 6367 for kilometers\n",
    "    return mi, dlon, dlat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#apply haversine function to training dataset, creating a column called 'dist_from_ohare_MI'\n",
    "final_df['dist_from_ohare_MI'] = [haversine(y, x, ohare_lon, ohare_lat)[0] for y, x in zip(lon, lat)]\n",
    "#apply haversine function to training dataset, creating a column called 'dist_from_doty_MI'\n",
    "final_df['dist_from_doty_MI'] = [haversine(y, x, doty_lon, doty_lat)[0] for y, x in zip(lon, lat)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Address', 'Block', 'Street', 'Trap', 'AddressNumberAndStreet',\n",
       "       'Latitude', 'Longitude', 'AddressAccuracy', 'NumMosquitos',\n",
       "       'WnvPresent', 'st1_Tmax', 'st1_Tmin', 'st1_Tavg', 'st1_DewPoint',\n",
       "       'st1_WetBulb', 'st1_CodeSum', 'st1_SnowFall', 'st1_PrecipTotal',\n",
       "       'st1_StnPressure', 'st1_SeaLevel', 'st1_ResultSpeed', 'st1_ResultDir',\n",
       "       'st1_AvgSpeed', 'st1_Lat', 'st1_Long', 'st2_Tmax', 'st2_Tmin',\n",
       "       'st2_Tavg', 'st2_DewPoint', 'st2_WetBulb', 'st2_CodeSum',\n",
       "       'st2_SnowFall', 'st2_PrecipTotal', 'st2_StnPressure', 'st2_SeaLevel',\n",
       "       'st2_ResultSpeed', 'st2_ResultDir', 'st2_AvgSpeed', 'st2_Lat',\n",
       "       'st2_Long', 'precip_avg', '2wk_precip', '4wk_precip', '90day_precip',\n",
       "       'temp_avg', '2wk_tavg', '4wk_tavg', '90day_tavg', 'tempmin_avg',\n",
       "       '2wk_mintemp', '4wk_mintemp', 'dew_avg', '2wk_dew', '4wk_dew',\n",
       "       'Species_CULEX ERRATICUS', 'Species_CULEX PIPIENS',\n",
       "       'Species_CULEX PIPIENS/RESTUANS', 'Species_CULEX RESTUANS',\n",
       "       'Species_CULEX SALINARIUS', 'Species_CULEX TARSALIS',\n",
       "       'Species_CULEX TERRITANS', 'Month', 'Day', 'dist_from_ohare_MI',\n",
       "       'dist_from_doty_MI'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_features = final_df[['Latitude', 'Longitude', 'st1_Tmax', 'st1_Tmin', 'st1_Tavg', 'st1_DewPoint', 'st1_WetBulb', 'st1_SnowFall', 'st1_PrecipTotal', 'st1_StnPressure', 'st1_SeaLevel', 'st1_ResultSpeed', 'st1_ResultDir', 'st1_AvgSpeed', 'st2_Tmax', 'st2_Tmin', 'st2_Tavg', 'st2_DewPoint', 'st2_WetBulb', 'st2_SnowFall', 'st2_PrecipTotal', 'st2_StnPressure', 'st2_SeaLevel', 'st2_ResultSpeed', 'st2_ResultDir', 'st2_AvgSpeed', 'precip_avg', '2wk_precip', '4wk_precip', '90day_precip', 'temp_avg', '2wk_tavg', '4wk_tavg', '90day_tavg', 'tempmin_avg', '2wk_mintemp', '4wk_mintemp', 'dew_avg', '2wk_dew', '4wk_dew', 'Species_CULEX ERRATICUS', 'Species_CULEX PIPIENS', 'Species_CULEX PIPIENS/RESTUANS', 'Species_CULEX RESTUANS', 'Species_CULEX SALINARIUS', 'Species_CULEX TARSALIS', 'Species_CULEX TERRITANS', 'Month', 'Day', 'dist_from_ohare_MI', 'dist_from_doty_MI']]\n",
    "target = final_df.WnvPresent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scale = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_features = pd.DataFrame(scale.fit_transform(test_features), columns=test_features.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(test_features, target, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, roc_auc_score\n",
    "\n",
    "def eval_sklearn_model(y_true, predictions, model=None, X=None):\n",
    "    \"\"\"This function takes the true values for y and the predictions made by the model and prints out the confusion matrix along with Accuracy, Precision, and, if model and X provided, Roc_Auc Scores.\"\"\"\n",
    "    cnf_matrix = confusion_matrix(y_true, predictions)\n",
    "\n",
    "    print('True Negative: ', cnf_matrix[0, 0], '| False Positive: ', cnf_matrix[0, 1])\n",
    "    print('False Negative: ', cnf_matrix[1, 0], '| True Positive: ', cnf_matrix[1, 1], '\\n')\n",
    "\n",
    "    sensitivity = cnf_matrix[1, 1]/ (cnf_matrix[1, 0] + cnf_matrix[1, 1])\n",
    "    specificity = cnf_matrix[0, 0]/ (cnf_matrix[0, 1] + cnf_matrix[0, 0])\n",
    "\n",
    "    print('Sensitivity (TP/ TP + FN): ', sensitivity)\n",
    "    print('Specificity (TN/ TN + FP): ', specificity, '\\n')\n",
    "\n",
    "    print('Accuracy: ', accuracy_score(y_true, predictions, normalize=True))\n",
    "    print('Precision: ', precision_score(y_true, predictions))\n",
    "    if model != None:\n",
    "        print('Roc-Auc: ', roc_auc_score(y_true, [x[1] for x in model.predict_proba(X)]))\n",
    "    else:\n",
    "        pass\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here are some models and Grid Searches\n",
    "\n",
    "More are found in the folder titled 'models'.  You can skip down to the Final Model section to run our final model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
       "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
       "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=18.101298701298703, seed=0, silent=True,\n",
       "       subsample=1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier(scale_pos_weight=(6969/385), objective='binary:logistic')\n",
    "# make sure to pick the correct objective for the problem\n",
    "# scale_pos_weight is supposed to help with unbalanced classes; it recommended number of negative cases divided by positive\n",
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative:  2270 | False Positive:  716\n",
      "False Negative:  33 | True Positive:  133 \n",
      "\n",
      "Sensitivity (TP/ TP + FN):  0.801204819277\n",
      "Specificity (TN/ TN + FP):  0.760214333557 \n",
      "\n",
      "Accuracy:  0.762373096447\n",
      "Precision:  0.156654888104\n",
      "Roc-Auc:  0.847410405184\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_predictions = xgb.predict(X_test)\n",
    "eval_sklearn_model(y_test, test_predictions, model=xgb, X=X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra Random Forest TEST SCORE:\n",
      "\n",
      "True Negative:  2423 | False Positive:  563\n",
      "False Negative:  52 | True Positive:  114 \n",
      "\n",
      "Sensitivity (TP/ TP + FN):  0.686746987952\n",
      "Specificity (TN/ TN + FP):  0.811453449431 \n",
      "\n",
      "Accuracy:  0.804885786802\n",
      "Precision:  0.168389955687\n",
      "Roc-Auc:  0.839361800854\n",
      "\n",
      "\n",
      "Wall time: 361 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "etc = ExtraTreesClassifier(class_weight='balanced', max_features='sqrt', min_samples_leaf=5, n_estimators=100, n_jobs=-1)\n",
    "etc.fit(X_train, y_train)\n",
    "test_predictions = etc.predict(X_test)\n",
    "print('Extra Random Forest TEST SCORE:\\n')\n",
    "eval_sklearn_model(y_test, test_predictions,model=etc,X=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest TEST SCORE:\n",
      "\n",
      "True Negative:  2731 | False Positive:  255\n",
      "False Negative:  90 | True Positive:  76 \n",
      "\n",
      "Sensitivity (TP/ TP + FN):  0.457831325301\n",
      "Specificity (TN/ TN + FP):  0.914601473543 \n",
      "\n",
      "Accuracy:  0.890545685279\n",
      "Precision:  0.229607250755\n",
      "Roc-Auc:  0.839361800854\n",
      "\n",
      "\n",
      "Wall time: 1.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rfc = RandomForestClassifier(class_weight='balanced', max_features='sqrt', min_samples_leaf=5, n_estimators=1000, n_jobs=-1)\n",
    "rfc.fit(X_train, y_train)\n",
    "test_predictions = rfc.predict(X_test)\n",
    "print('Random Forest TEST SCORE:\\n')\n",
    "eval_sklearn_model(y_test, test_predictions,model=etc,X=X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Models Run:  120\n",
      "Decision Tree Classifier Score: 0.798 \n",
      "\n",
      "Elapsed Time: 1.39e+02  seconds \n",
      "\n",
      "ExtraTreesClassifier(bootstrap=False, class_weight='balanced',\n",
      "           criterion='gini', max_depth=None, max_features='sqrt',\n",
      "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "           min_impurity_split=None, min_samples_leaf=6,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=1000, n_jobs=-1, oob_score=False,\n",
      "           random_state=None, verbose=0, warm_start=False) \n",
      "\n",
      "Best Hyperparameters we tested for \n",
      " {'params': [('max_features', 'sqrt'), ('min_samples_leaf', 6), ('n_estimators', 1000)], 'score': 0.79040803737396559}\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Pick which estimators you want to test (example is for random forest)\n",
    "param_grid = dict(n_estimators = [100, 1000],\n",
    "                 max_features = [10, 20, 30, 'sqrt'],\n",
    "                 min_samples_leaf = [2, 3, 4, 5, 6],\n",
    "                 )\n",
    "# How many cross validation folds do you want?\n",
    "cross_val=3\n",
    "\n",
    "# Switch out the model here that you would like to test\n",
    "model = ExtraTreesClassifier(class_weight='balanced', n_jobs=-1)\n",
    "\n",
    "grid = GridSearchCV(model, param_grid, cv=cross_val, scoring='roc_auc', verbose=1)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "best_results = {'params': list(grid.best_params_.items()), 'score': grid.best_score_}\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "\n",
    "best_model = best_model.fit(X_train, y_train)\n",
    "\n",
    "score = best_model.score(X_test, y_test)\n",
    "\n",
    "print('Number of Models Run: ', np.prod([len(param_grid[i]) for i in param_grid]) * cross_val)\n",
    "print(\"{} Score: {:0.3}\".format('Decision Tree Classifier', score.mean().round(3)), '\\n')\n",
    "print('Elapsed Time: {:0.3}'.format( time.time() - start_time), ' seconds', '\\n')\n",
    "print(grid.best_estimator_, '\\n')\n",
    "print('Best Hyperparameters we tested for', '\\n', best_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search TEST SCORE:\n",
      "\n",
      "True Negative:  2398 | False Positive:  588\n",
      "False Negative:  49 | True Positive:  117 \n",
      "\n",
      "Sensitivity (TP/ TP + FN):  0.704819277108\n",
      "Specificity (TN/ TN + FP):  0.803081044876 \n",
      "\n",
      "Accuracy:  0.797906091371\n",
      "Precision:  0.165957446809\n",
      "Roc-Auc:  0.842486826072\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Your best model from the grid is already fit and saved as best_model\n",
    "test_predictions = best_model.predict(X_test)\n",
    "print('Grid Search TEST SCORE:\\n')\n",
    "# function created above should be run before this cell\n",
    "eval_sklearn_model(y_test, test_predictions, model=best_model, X=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:  6.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Models Run:  120\n",
      "Decision Tree Classifier Score: 0.899 \n",
      "\n",
      "Elapsed Time: 4.21e+02  seconds \n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=None, max_features=20,\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=6,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=1000, n_jobs=-1, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False) \n",
      "\n",
      "Best Hyperparameters we tested for \n",
      " {'params': [('max_features', 20), ('min_samples_leaf', 6), ('n_estimators', 1000)], 'score': 0.80202909231930231}\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Pick which estimators you want to test (example is for random forest)\n",
    "param_grid = dict(n_estimators = [1000, 2000],\n",
    "                 max_features = [10, 20, 30, 'sqrt'],\n",
    "                 min_samples_leaf = [2, 3, 4, 5, 6],\n",
    "                 )\n",
    "# How many cross validation folds do you want?\n",
    "cross_val=3\n",
    "\n",
    "# Switch out the model here that you would like to test\n",
    "model = RandomForestClassifier(class_weight='balanced', n_jobs=-1)\n",
    "\n",
    "grid = GridSearchCV(model, param_grid, cv=cross_val, scoring='roc_auc', verbose=1)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "best_results = {'params': list(grid.best_params_.items()), 'score': grid.best_score_}\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "\n",
    "best_model = best_model.fit(X_train, y_train)\n",
    "\n",
    "score = best_model.score(X_test, y_test)\n",
    "\n",
    "print('Number of Models Run: ', np.prod([len(param_grid[i]) for i in param_grid]) * cross_val)\n",
    "print(\"{} Score: {:0.3}\".format('Decision Tree Classifier', score.mean().round(3)), '\\n')\n",
    "print('Elapsed Time: {:0.3}'.format( time.time() - start_time), ' seconds', '\\n')\n",
    "print(grid.best_estimator_, '\\n')\n",
    "print('Best Hyperparameters we tested for', '\\n', best_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search TEST SCORE:\n",
      "\n",
      "True Negative:  2762 | False Positive:  224\n",
      "False Negative:  95 | True Positive:  71 \n",
      "\n",
      "Sensitivity (TP/ TP + FN):  0.427710843373\n",
      "Specificity (TN/ TN + FP):  0.924983255191 \n",
      "\n",
      "Accuracy:  0.898794416244\n",
      "Precision:  0.240677966102\n",
      "Roc-Auc:  0.841158337301\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Your best model from the grid is already fit and saved as best_model\n",
    "test_predictions = best_model.predict(X_test)\n",
    "print('Grid Search TEST SCORE:\\n')\n",
    "# function created above should be run before this cell\n",
    "eval_sklearn_model(y_test, test_predictions, model=best_model, X=X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>import</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Day</td>\n",
       "      <td>0.123397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Longitude</td>\n",
       "      <td>0.100915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>dist_from_ohare_MI</td>\n",
       "      <td>0.086271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>4wk_dew</td>\n",
       "      <td>0.081232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>dist_from_doty_MI</td>\n",
       "      <td>0.074891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Latitude</td>\n",
       "      <td>0.074716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>90day_tavg</td>\n",
       "      <td>0.054776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Month</td>\n",
       "      <td>0.042208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>4wk_tavg</td>\n",
       "      <td>0.034593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>4wk_mintemp</td>\n",
       "      <td>0.025118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>st2_ResultSpeed</td>\n",
       "      <td>0.020467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2wk_tavg</td>\n",
       "      <td>0.018703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Species_CULEX PIPIENS/RESTUANS</td>\n",
       "      <td>0.018030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2wk_dew</td>\n",
       "      <td>0.017803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Species_CULEX RESTUANS</td>\n",
       "      <td>0.016864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>90day_precip</td>\n",
       "      <td>0.016047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Species_CULEX PIPIENS</td>\n",
       "      <td>0.015010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>st1_ResultSpeed</td>\n",
       "      <td>0.013807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>st1_AvgSpeed</td>\n",
       "      <td>0.012220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>st2_AvgSpeed</td>\n",
       "      <td>0.010567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>st1_Tmax</td>\n",
       "      <td>0.009464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>temp_avg</td>\n",
       "      <td>0.009389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2wk_mintemp</td>\n",
       "      <td>0.009080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2wk_precip</td>\n",
       "      <td>0.008707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4wk_precip</td>\n",
       "      <td>0.008594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>st2_Tmin</td>\n",
       "      <td>0.007950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>st2_StnPressure</td>\n",
       "      <td>0.006917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>st2_Tmax</td>\n",
       "      <td>0.006778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>st1_Tavg</td>\n",
       "      <td>0.006586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>st2_ResultDir</td>\n",
       "      <td>0.006364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>st1_StnPressure</td>\n",
       "      <td>0.006353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>st1_ResultDir</td>\n",
       "      <td>0.005691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>st2_SeaLevel</td>\n",
       "      <td>0.004887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>st2_Tavg</td>\n",
       "      <td>0.004743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>st1_Tmin</td>\n",
       "      <td>0.004622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>tempmin_avg</td>\n",
       "      <td>0.004523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>st1_SeaLevel</td>\n",
       "      <td>0.004506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>precip_avg</td>\n",
       "      <td>0.003790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>st1_PrecipTotal</td>\n",
       "      <td>0.003565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>st2_WetBulb</td>\n",
       "      <td>0.003539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>dew_avg</td>\n",
       "      <td>0.003244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>st1_WetBulb</td>\n",
       "      <td>0.002983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>st1_DewPoint</td>\n",
       "      <td>0.002921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>st2_PrecipTotal</td>\n",
       "      <td>0.002744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>st2_DewPoint</td>\n",
       "      <td>0.002622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Species_CULEX TERRITANS</td>\n",
       "      <td>0.001804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Species_CULEX ERRATICUS</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Species_CULEX SALINARIUS</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Species_CULEX TARSALIS</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>st2_SnowFall</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>st1_SnowFall</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           feature    import\n",
       "48                             Day  0.123397\n",
       "1                        Longitude  0.100915\n",
       "49              dist_from_ohare_MI  0.086271\n",
       "39                         4wk_dew  0.081232\n",
       "50               dist_from_doty_MI  0.074891\n",
       "0                         Latitude  0.074716\n",
       "33                      90day_tavg  0.054776\n",
       "47                           Month  0.042208\n",
       "32                        4wk_tavg  0.034593\n",
       "36                     4wk_mintemp  0.025118\n",
       "23                 st2_ResultSpeed  0.020467\n",
       "31                        2wk_tavg  0.018703\n",
       "42  Species_CULEX PIPIENS/RESTUANS  0.018030\n",
       "38                         2wk_dew  0.017803\n",
       "43          Species_CULEX RESTUANS  0.016864\n",
       "29                    90day_precip  0.016047\n",
       "41           Species_CULEX PIPIENS  0.015010\n",
       "11                 st1_ResultSpeed  0.013807\n",
       "13                    st1_AvgSpeed  0.012220\n",
       "25                    st2_AvgSpeed  0.010567\n",
       "2                         st1_Tmax  0.009464\n",
       "30                        temp_avg  0.009389\n",
       "35                     2wk_mintemp  0.009080\n",
       "27                      2wk_precip  0.008707\n",
       "28                      4wk_precip  0.008594\n",
       "15                        st2_Tmin  0.007950\n",
       "21                 st2_StnPressure  0.006917\n",
       "14                        st2_Tmax  0.006778\n",
       "4                         st1_Tavg  0.006586\n",
       "24                   st2_ResultDir  0.006364\n",
       "9                  st1_StnPressure  0.006353\n",
       "12                   st1_ResultDir  0.005691\n",
       "22                    st2_SeaLevel  0.004887\n",
       "16                        st2_Tavg  0.004743\n",
       "3                         st1_Tmin  0.004622\n",
       "34                     tempmin_avg  0.004523\n",
       "10                    st1_SeaLevel  0.004506\n",
       "26                      precip_avg  0.003790\n",
       "8                  st1_PrecipTotal  0.003565\n",
       "18                     st2_WetBulb  0.003539\n",
       "37                         dew_avg  0.003244\n",
       "6                      st1_WetBulb  0.002983\n",
       "5                     st1_DewPoint  0.002921\n",
       "20                 st2_PrecipTotal  0.002744\n",
       "17                    st2_DewPoint  0.002622\n",
       "46         Species_CULEX TERRITANS  0.001804\n",
       "40         Species_CULEX ERRATICUS  0.000000\n",
       "44        Species_CULEX SALINARIUS  0.000000\n",
       "45          Species_CULEX TARSALIS  0.000000\n",
       "19                    st2_SnowFall  0.000000\n",
       "7                     st1_SnowFall  0.000000"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_import = best_model.feature_importances_\n",
    "features = X_train.columns\n",
    "pd.DataFrame(columns=['feature', 'import'], data=list(zip(features, feature_import))).sort_values('import',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model\n",
    "\n",
    "Based on grid searching and testing of other models as seen in models found in model folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_features = test_features.drop(['st1_SnowFall', 'st2_SnowFall', 'Species_CULEX TARSALIS', 'Species_CULEX SALINARIUS', 'Species_CULEX ERRATICUS', 'Species_CULEX TERRITANS', 'st2_DewPoint', 'st2_PrecipTotal', 'st1_DewPoint', 'st1_WetBulb', 'dew_avg', 'st2_WetBulb', 'st1_PrecipTotal', 'precip_avg', 'st1_SeaLevel', 'tempmin_avg', 'st1_Tmin', 'st2_Tavg', 'st2_SeaLevel',], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(test_features, target, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Train/Test Score:\n",
      "\n",
      "True Negative:  2112 | False Positive:  874\n",
      "False Negative:  30 | True Positive:  136 \n",
      "\n",
      "Sensitivity (TP/ TP + FN):  0.819277108434\n",
      "Specificity (TN/ TN + FP):  0.707300736772 \n",
      "\n",
      "Accuracy:  0.713197969543\n",
      "Precision:  0.134653465347\n",
      "Roc-Auc:  0.839673496397\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(scale_pos_weight=(6969/385), objective='binary:logistic', gamma=0.35, learning_rate=0.02, max_depth=3, n_estimators=200)\n",
    "xgb.fit(X_train, y_train)\n",
    "test_predictions = xgb.predict(X_test)\n",
    "print('XGBoost Train/Test Score:\\n')\n",
    "eval_sklearn_model(y_test, test_predictions, model=xgb, X=X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up test data and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('assets/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test[\"Date\"] = pd.to_datetime(test[\"Date\"], infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test[\"Date\"] = pd.to_datetime(test[\"Date\"], infer_datetime_format=True)\n",
    "test['Address'] = test['Address'].astype('category')\n",
    "test['Species'] = test['Species'].astype('category')\n",
    "test['Street'] = test['Street'].astype('category')\n",
    "test['Trap'] = test['Trap'].astype('category')\n",
    "test['AddressNumberAndStreet'] = test['AddressNumberAndStreet'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.merge(test, weather, how='left', on='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.get_dummies(test, columns=['Species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['Month'] = test['Date'].dt.month\n",
    "test[\"Day\"] = test['Date'].dt.dayofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lat = test.Latitude\n",
    "lon = test.Longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#apply haversine function to training dataset, creating a column called 'dist_from_ohare_MI'\n",
    "test['dist_from_ohare_MI'] = [haversine(y, x, ohare_lon, ohare_lat)[0] for y, x in zip(lon, lat)]\n",
    "#apply haversine function to training dataset, creating a column called 'dist_from_doty_MI'\n",
    "test['dist_from_doty_MI'] = [haversine(y, x, doty_lon, doty_lat)[0] for y, x in zip(lon, lat)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make match above\n",
    "pred_features = test[['Latitude', 'Longitude', 'st1_Tmax', 'st1_Tmin', 'st1_Tavg', 'st1_DewPoint', 'st1_WetBulb', 'st1_SnowFall', 'st1_PrecipTotal', 'st1_StnPressure', 'st1_SeaLevel', 'st1_ResultSpeed', 'st1_ResultDir', 'st1_AvgSpeed', 'st2_Tmax', 'st2_Tmin', 'st2_Tavg', 'st2_DewPoint', 'st2_WetBulb', 'st2_SnowFall', 'st2_PrecipTotal', 'st2_StnPressure', 'st2_SeaLevel', 'st2_ResultSpeed', 'st2_ResultDir', 'st2_AvgSpeed', 'precip_avg', '2wk_precip', '4wk_precip', '90day_precip', 'temp_avg', '2wk_tavg', '4wk_tavg', '90day_tavg', 'tempmin_avg', '2wk_mintemp', '4wk_mintemp', 'dew_avg', '2wk_dew', '4wk_dew', 'Species_CULEX ERRATICUS', 'Species_CULEX PIPIENS', 'Species_CULEX PIPIENS/RESTUANS', 'Species_CULEX RESTUANS', 'Species_CULEX SALINARIUS', 'Species_CULEX TARSALIS', 'Species_CULEX TERRITANS', 'Month', 'Day', 'dist_from_ohare_MI', 'dist_from_doty_MI']]\n",
    "pred_features = pred_features.drop(['st1_SnowFall', 'st2_SnowFall', 'Species_CULEX TARSALIS', 'Species_CULEX SALINARIUS', 'Species_CULEX ERRATICUS', 'Species_CULEX TERRITANS', 'st2_DewPoint', 'st2_PrecipTotal', 'st1_DewPoint', 'st1_WetBulb', 'dew_avg', 'st2_WetBulb', 'st1_PrecipTotal', 'precip_avg', 'st1_SeaLevel', 'tempmin_avg', 'st1_Tmin', 'st2_Tavg', 'st2_SeaLevel',], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CHECK QUICK\n",
    "pred_features = pd.DataFrame(scale.fit_transform(pred_features), columns=pred_features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Whatever model you decided on:\n",
    "predictions = xgb.predict(pred_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission Shape:  (116293, 1) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "submission = pd.DataFrame(columns=['Id', 'WnvPresent'], data=list(zip(test.Id, predictions)))\n",
    "submission = submission.set_index('Id')\n",
    "print('Submission Shape: ', submission.shape, '\\n')\n",
    "print('Submission Results: \\n', submission['WnvPresent'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict_Proba\n",
    "\n",
    "For Kaggle submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whatever model you decided on:\n",
    "predictions = xgb.predict_proba(pred_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = xgb.predict_proba(pred_features)\n",
    "submission = pd.DataFrame(columns=['Id', 'WnvPresent'], data=list(zip(test.Id, predictions)))\n",
    "print('Submission Shape: ', submission.shape, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.WnvPresent = submission.WnvPresent.apply(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
